import os
import re
import time
import json
import pandas as pd
import matplotlib.pyplot as plt
import networkx as nx
from openai import OpenAI

# åˆå§‹åŒ– OpenAI
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ==============================
# å·¥å…·å‡½å¼
# ==============================

def safe_json_parse(s: str):
    """ä¿éšªçš„ JSON parserï¼Œé¿å…æ¨¡å‹è¼¸å‡ºä¸ä¹¾æ·¨"""
    try:
        return json.loads(s)
    except json.JSONDecodeError:
        match = re.search(r"\[.*\]", s, re.DOTALL)
        if match:
            return json.loads(match.group(0))
        else:
            print("âš ï¸ æ¨¡å‹è¼¸å‡ºé JSONï¼š", s)
            return []

def log_error(idx, report_text, error):
    """ç´€éŒ„å¤±æ•—æ¡ˆä¾‹"""
    with open("error_log.txt", "a", encoding="utf-8") as logf:
        logf.write(f"âŒ ç¬¬ {idx+1} ç­†å¤±æ•—: {error}\n")
        logf.write(f"å ±å‘Šå…§å®¹: {report_text[:200]}...\n\n")

def call_openai_with_retry(prompt, idx, report_text, retries=3, timeout=60.0):
    """å‘¼å« GPTï¼Œå…§å»º retry æ©Ÿåˆ¶"""
    for i in range(retries):
        try:
            return client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0,
                timeout=timeout
            )
        except Exception as e:
            print(f"âš ï¸ ç¬¬ {idx+1} ç­†ï¼Œç¬¬ {i+1} æ¬¡å¤±æ•—: {e}")
            if i == retries - 1:
                log_error(idx, report_text, str(e))
            time.sleep(2 ** i)
    return None

# ==============================
# æ–°ç‰ˆç·¨ç¢¼è¦å‰‡
# ==============================

final_codes = {"0","1","2","3","4","5","7","8","9","A","B","C","D","E","F"}

Rule = """
ç·¨ç¢¼,å®šç¾©åŸç™¼éƒ¨ä½æ‰‹è¡“é‚Šç·£ç·¨ç¢¼è¦å‰‡
0,æ‰‹è¡“ç´€éŒ„æè¿°ç„¡æ®˜å­˜è…«ç˜¤ã€‚ç—…ç†å ±å‘Šæè¿°ã€ŒUninvolvedã€ã€‚
1,åªçŸ¥é“æœ‰æ®˜å­˜çš„ä¾µè¥²æ€§ç™Œç´°èƒï¼Œè‡³æ–¼å…¶ä»–æ›´è©³ç´°çš„æƒ…å½¢å‰‡ä¸æ¸…æ¥šï¼Œæ‰‹è¡“ç´€éŒ„æè¿°ç„¡æ®˜å­˜è…«ç˜¤ã€‚
2,ç—…ç†å ±å‘Šä¸­å·¨è§€ç„¡æ®˜å­˜è…«ç˜¤ï¼Œä¸”æ‰‹è¡“ç´€éŒ„æè¿°ç„¡æ®˜å­˜è…«ç˜¤ï¼Œåƒ…åœ¨é¡¯å¾®é¡ä¸‹çœ‹åˆ°æ®˜å­˜çš„ä¾µè¥²æ€§ç™Œç´°èƒã€‚ç—…ç†å ±å‘Šæè¿°ã€Œinvolvedã€ã€‚
3,ç—…ç†å ±å‘Šæè¿°åœ¨è‚‰çœ¼ä¸‹å°±å¯ä»¥çœ‹åˆ°æ®˜å­˜çš„ä¾µè¥²æ€§ç™Œç´°èƒï¼Œé¡¯å¾®é¡ä¸‹åŠæ‰‹è¡“ç´€éŒ„çš†ç„¡æè¿°æ‰‹è¡“é‚Šç·£ç‹€æ…‹ã€‚
4,ç—…ç†å ±å‘Šåœ¨è‚‰çœ¼åŠé¡¯å¾®é¡ä¸‹çš†çœ‹åˆ°æ®˜å­˜çš„ä¾µè¥²æ€§ç™Œç´°èƒï¼Œæ‰‹è¡“ç´€éŒ„æè¿°ç„¡æ®˜å­˜è…«ç˜¤ã€‚
5,ç—…ç†å ±å‘Šæè¿°ä¾µè¥²ç™Œæ‰‹è¡“é‚Šç·£ç‹€æ…‹ç‚ºvery closeæˆ–may not be freeã€‚ä¾µè¥²ç™Œç—…ç†å ±å‘Šåƒ…æè¿°<1mmä¸”æœªæ˜ç¤ºæ‰‹è¡“é‚Šç·£ç‹€æ…‹ã€‚
7,ç—…ç†å ±å‘Šæè¿°æ‰‹è¡“é‚Šç·£ç‹€æ…‹ç„¡æ³•è©•ä¼°ã€‚
8,æœªé‡å°åŸç™¼è…«ç˜¤éƒ¨ä½é€²è¡Œæ‰‹è¡“ã€‚æ‰‹è¡“æ–¹å¼ç·¨ç¢¼ç‚º10-19è€…ã€‚æ”è­·è…ºç™Œå€‹æ¡ˆåƒ…æ¥å—TURPã€‚
A,æ‰‹è¡“ç´€éŒ„æè¿°æœ‰æ®˜å­˜è…«ç˜¤ï¼Œæˆ–ç‚ºè…«ç˜¤éƒ¨ä»½åˆ‡é™¤(R2 resection)ï¼Œä½†ç—…ç†å ±å‘Šæè¿°ç„¡æ®˜å­˜è…«ç˜¤ã€ç„¡æ³•è©•ä¼°æˆ–ä¸æ¸…æ¥šã€‚
B,æ‰‹è¡“ç´€éŒ„æè¿°æœ‰æ®˜å­˜è…«ç˜¤ï¼Œæˆ–ç‚ºè…«ç˜¤éƒ¨ä»½åˆ‡é™¤(R2 resection)ï¼ŒåŒæ™‚ç—…ç†å ±å‘Šæè¿°äº¦æœ‰æ®˜å­˜ä¾µè¥²æ€§ç™Œç´°èƒã€‚
C,ç—…ç†å ±å‘Šæè¿°æ‰‹è¡“é‚Šç·£ç‚º high gradeã€moderate dysplasiaã€severe dysplasiaã€carcinoma in situã€‚
D,ç—…ç†å ±å‘Šæè¿°æ‰‹è¡“é‚Šç·£ç‚º mild dysplasia or low gradeã€‚
E,ç—…ç†å ±å‘Šæè¿°æ‰‹è¡“é‚Šç·£ç‚º dysplasiaï¼Œæœªæ˜ç¤ºç‚º high or low gradeã€‚
F,ç—…ç†å ±å‘Šæè¿°åŸä½ç™Œ/åˆ†åŒ–ä¸è‰¯æ‰‹è¡“é‚Šç·£ç‹€æ…‹ç‚º very close æˆ– may not be freeã€‚ç—…ç†å ±å‘Šåƒ…æè¿° <1mm ä¸”æœªæ˜ç¤ºæ‰‹è¡“é‚Šç·£ç‹€æ…‹ã€‚
9,ä¸çŸ¥é“å€‹æ¡ˆæ˜¯å¦æœ‰æ¥å—åŸç™¼éƒ¨ä½æ‰‹è¡“ã€‚åŸç™¼éƒ¨ä½ç‚ºæ·‹å·´çµçš„æ·‹å·´ç™Œã€åŸç™¼ä¸æ˜æˆ–ç—…æ­·æœªè¨˜è¼‰ã€‚
"""

# ==============================
# Triple Builder
# ==============================

def connect_isolated_nodes(triples, correct_code, evidence_sentence="__bridge__"):
    """é¿å…å­¤ç«‹ç¯€é»ï¼Œå¼·åˆ¶æ¥åˆ°æ­£ç¢º code"""
    G = nx.DiGraph()
    for t in triples:
        G.add_edge(t["subject"], t["object"])

    connected = set()
    for node in G.nodes:
        if correct_code in G.nodes and nx.has_path(G, node, correct_code):
            connected.add(node)

    isolated = [n for n in G.nodes if n not in connected and n not in final_codes]

    for node in isolated:
        triples.append({
            "subject": node,
            "relation": "leads_to",
            "object": correct_code,
            "evidence_sentence": evidence_sentence
        })
    return triples

def build_graph_from_labeled(report_text, correct_code, Rule, idx=0):
    """å‘¼å« GPT ç”Ÿæˆä¸‰å…ƒçµ„"""
    prompt = f"""
ä½ æ˜¯ä¸€å€‹ç™Œç—‡ç™»è¨˜çŸ¥è­˜åœ–è­œå»ºæ§‹åŠ©æ‰‹ã€‚  
è¼¸å…¥æœ‰ï¼š(1) ç—…ç†å ±å‘Šå…¨æ–‡ (reportData)ï¼Œ(2) å·²çŸ¥çš„æ­£ç¢ºçµ‚ç«¯ç·¨ç¢¼ (correct_code)ã€‚  
ä»»å‹™ï¼šè¼¸å‡º JSON é™£åˆ—ï¼Œæ¯ç­†æ˜¯ (subject, relation, object)ã€‚

ã€çµ‚ç«¯ç·¨ç¢¼é›†åˆã€‘  
åªèƒ½ä½¿ç”¨é€™äº›ä»£ç¢¼: ["0","1","2","3","4","5","7","8","9","A","B","C","D","E","F"]  

{Rule}

ã€è¦å‰‡ã€‘  
1. subject/object å¿…é ˆä¾†è‡ª reportData çš„ç‰‡æ®µ (trim å¯) æˆ–æ­£ç¢º codeï¼Œä¸å¯æé€ ã€‚  
2. relation åªèƒ½é¸æ“‡: ["status","associated_with","location","measured_in","type_of","evaluation","implies_code","leads_to","corresponds_to"]  
3. è‡³å°‘æœ‰ä¸€æ¢æ¨ç†éˆï¼Œæœ€å¾Œå¿…é ˆåˆ°æ­£ç¢º code "{correct_code}"ã€‚  
4. è«‹ç¢ºä¿æ²’æœ‰å­¤ç«‹ç¯€é»ã€‚  
5. è¼¸å‡ºå¿…é ˆæ˜¯ç´” JSON é™£åˆ—ã€‚  

ã€è¼¸å…¥ã€‘  
reportData:  
{report_text}
"""
    response = call_openai_with_retry(prompt, idx, report_text)
    if response is None:
        return []

    raw_output = response.choices[0].message.content.strip()
    triples = safe_json_parse(raw_output)
    triples = connect_isolated_nodes(triples, correct_code)
    return triples


# ==============================
# ä¸»ç¨‹å¼
# ==============================

if __name__ == "__main__":
    INPUT_CSV = "/home/st426/system/global_graph/data/sur/reportDataå’ŒåŸç™¼éƒ¨ä½æ‰‹è¡“é‚Šç·£.csv"
    OUTPUT_DIR = "/home/st426/system/global_graph/graph_sur"
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    df = pd.read_csv(INPUT_CSV)
    big_graph = []
    output_file = os.path.join(OUTPUT_DIR, "surgical_margin_graph.json")

    for idx, row in df.iterrows():
        report_text = str(row["reportData"])
        correct_code = str(row["åŸç™¼éƒ¨ä½æ‰‹è¡“é‚Šç·£"]).strip()

        triples = build_graph_from_labeled(report_text, correct_code, Rule, idx)
        big_graph.extend(triples)

        # æ›´æ–° JSON
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(big_graph, f, indent=2, ensure_ascii=False)


        print(f"âœ… ç¬¬ {idx+1} ç­†å®Œæˆ, ç´¯ç© {len(big_graph)} æ¢")

    print(f"ğŸ‰ å¤§åœ–å®Œæˆ â†’ {output_file}")
    print("ğŸ“„ éŒ¯èª¤è«‹æŸ¥çœ‹ error_log.txt")
